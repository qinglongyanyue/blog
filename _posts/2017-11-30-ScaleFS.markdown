---
layout: default
title:  "ScaleFS分析"
date:   2017-10-29
categories: filesystem
---

ScaleFS是SOSP17，MIT做的一个多核文件系统，简单分析下他的设计方案。

## 总体架构

![]({{ site.baseurl }}/assets/scalefs-1.png)

ScaleFS包括2个FS，一个MEMFS，一个DiskFS。

- MEMFS：使用并发内存数据结构，实现内存操作的多核扩展，让多数操作免锁
- DISKFS：组织磁盘块，实现空间管理

2个文件系统之间通过一个op-log关联；这个log保存目录的所有变化，包括link，unlink，rename等。当需要刷盘时，直接从oplog收集这些操作，并下盘。

MEMFS与DiskFS相互独立，使用不同的inode号，为了方便区分，文中未mnode代表MEMFS的inode，inode代表DISK中的inode。有个表格记录mnode到inode的映射。

这样使得mnode的分配速度非常快，不需要访问磁盘，比如可以每个核分配一个mnode范围，这样也无需加锁。但是在重启之后，stat就会发现inode有变化。目前来看，依赖inode号不变的应用不多（主要指本地FS，NFS还是必须要inode号的）。

MEMFS包括：

- 一个page cache，每个file使用一个radix array来存放热点数据，脏的写也在这里，通过bitmap标识。
- 一个dentry hash表，映射文件名到mnode号；这个表是无锁的，对于每个dentry条目的修改是需要加锁的。另外有一篇论文专门讲这个。

DiskFS：

- 实现一个传统的磁盘文件系统，使用物理journal来将修改刷到磁盘中；为了更好的扩展性，DiskFS使用多个物理journal。
- DiskFS自己也维护一个buffer，缓存一些磁盘数据结构，比如空间分配表，inode表之类的；但是DiskFS并不做数据的cache。

一个oplog层来实现2层之间的交互，他主要做以下事情：

## 细节设计

### 记录操作的顺序

为了保证crash一致性，所有的操作必须按照一定的顺序加入到MEMFS的log中去。

所有的读操作都是不加锁的，使得如何确定不同操作的顺序会比较复杂。

比如一个场景，我们首先将每个操作log起来，log的过程中将需要的信息加锁，log完成之后解锁。

考虑一个简单的场景：

- dir1包含3个file names，a，b，c. a对应inode 1，b和c都对应inode 2.
- 线程T1提交rename调用，rename(b,c);线程T2提交rename(a,c).
- 假设线程T1先来，那么T1执行无锁的读取b和c，发现2者是同一个inode，那么直接删除dentry b，并减inode的引用；整个过程仅仅需要对b加锁。
- 接着T2过来，获取a和c的锁去执行rename；故T1和T2之间没有锁冲突，此时2者并发执行
- 由于T1先执行，T2后执行，此时MEMFS中c指向的inode为a的，即为1；
- 由于并发执行，可能T2先log完成，那么重放到盘之后，inode为b的，即为2，造成不一致。

ScaleFS的解决方案如下：

- 现代的CPU能够在不同的核之间提供准确的时间戳，这样就可以实现全局的oplog了
- 时间戳计数能够通过RDTSC命令获取
- 再这样的假设下，SCALEFS将内存中的dentry操作全局排序；即老的时间戳还没刷下去之前，新的时间戳的不让下去


基于时间戳的无所读：对于上面那个例子，需要保证T1 rename（b，c）的序列化点一定在T2 rename（a，c）之前，即T1读取到的 c一定在T2修改c之前。

- 为了确保在写的过程中，实现无锁的读取，MEMFS加了一个seqlock的逻辑（类似Linux内核的实现呢）；确保读发生在写操作之前。
- 使用seqlock的时候，写操作会对share的数据增加seqnum，写完再增加一次；读的开始和结束都会检查这个num，如果有变化，说明读的过程中有修改
- 如果发现过程中有修改，读retry，直到这个号不变
- MEMFS在修改之前都需要先读取，且能保证读取的都是正确的数据
- 每个读操作都有reqlock保护，并在其中读取时间戳；时间戳是一个很好的同步点（LP）

### merge操作

LP点能够很容易的实现多核之间的线性顺序，但是merge操作仍然要十分小心。

![]({{ site.baseurl }}/assets/scalefs-1.png)

- SCALEFS的每个核都有一个log，在fsync或sync的时候把多个核上的修改merge到一起。
- 假设2个并发任务op1和op2，分别在core1和core2执行；op1的LP先于op2，但是op2的log先完成，就上面描述的例子一样
- 如果这个时候刷log，就会造成不一致，如何解决：
  - 在merge的时候，检查所有人正在进行中的任务，如果有任务的LP点，比当前merge的操作要早，那么需要等待这个任务log之后才能刷下去

### 并发fsync动作