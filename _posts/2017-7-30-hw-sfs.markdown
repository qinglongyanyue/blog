---
layout: default
title:  "华为公有云SFS测试"
date:   2017-07-30
categories: filesystem
---

近期华为公有云SFS公测，啥也别说了，赶紧试试吧。

## 测试下VM之间的网络情况

由于nfs客户端和server之间的带宽很大程度上取决于网络，所以直接申请2台VM测试下带宽。使用iperf工具，一台server，一台client，结果如下：

```
server端：iperf -s
client端：iperf -c 192.168.1.185 -t 60

结果：
[  3]  0.0-60.0 sec  6.67 GBytes   955 Mbits/sec
```

测试结果来看，VM之间带宽为1Gbps，大约120MB/s，意味着一个客户端测试的带宽上限只能到120MB/s

## 挂载试用

目前只能支持华北的数据中心，可以创建多个SFS，不过挂在地址都是同一个，利用目录来分割租户。

Follow指导流程配置好DNS，直接挂载即可，目前仅支持NFSv3。

官方推荐用nolock挂载，不知为何，不够NFS3本身安全性就不好，无所谓了。
```
#mount -t nfs -o vers=3,nolock sfs.cn-north-1.hwclouds.com:/share-68672826-11a2-4685-9780-e5d322c6aa42 /tmp
```

其实挂载参数远不止这几个，只是剩下的都用默认的而已（如下grep命令可以看到所有的参数）：
```
＃grep /tmp /proc/mounts
sfs.cn-north-1.hwclouds.com:/share-68672826-11a2-4685-9780-e5d322c6aa42 /tmp nfs rw,relatime,vers=3,rsize=1048576,wsize=1048576,namlen=255,hard,nolock,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=100.125.13.35,mountvers=3,mountport=2050,mountproto=udp,local_lock=all,addr=100.125.13.35 0 0
```

## 单节点性能测试

由于主要想测试IOPS，单节点测试基本能达到目的。

### direct IO（不开client cache）性能测试
先测试一个VM使用NAS时的性能。

- VM配置：1核，1GB内存（乞丐版配置）
- VM内存性能；内存带宽大约5GB/s
- VM网络情况：带宽950Mb/s，大约120MB/s，ping的延迟大约300us
- 直接DD一个20GB的大文件先

```
root@ecs-c13c:/tmp# dd if=/dev/zero of=./test bs=1MB count=20000
20000+0 records in
20000+0 records out
20000000000 bytes (20 GB) copied, 161.083 s, 124 MB/s
```

#### Direct IO的latency

```
fio -filename=./test -direct=1 -iodepth 1 -thread -rw=write -ioengine=libaio -bs=4k -numjobs=1 -runtime=30 -group_reporting -name=mytest
```

- 测试方法：直接fio，4KB，队列深度为1，顺序/随机，读写30s，directIO。
 - 顺序写延时：平均4.3ms，236 IOPS
 - 随机写延时：26ms, 38 IOPS
 - 顺序读延时：489us，2030 IOPS
 - 随机读延时：20ms，47 IOPS
 - 随机或者顺序没有差别

 小压力下的延迟和IOPS性能差的触目惊心啊。。

#### Direct IO的带宽
- 测试方法：直接fio，1MB，队列深度为8，顺序，测试30秒，directIO
 - 写带宽：120MB/s左右
 - 读带宽：116MB/s左右

果然不是盖的，带宽一流，直接压慢一个VM。

#### Direct IO的IOPS
- 测试方法：直接fio，4KB，随机，测试30秒，directIO
 - 随机写IOPS：写IOPS能力极弱，32队列深度，IOPS 346，平均延迟100ms
 - 随机读IOPS：64队列深度，IOPS 1427，此时平均延迟45ms

## 实际场景测试
###  解压内核代码压缩包
-  测试环境：前述相同的VM，1C1G
-  方法：先用NAS的目录，然后用ext4的目录
-  为保证测试公平，每次测试都清空内存：echo 3 > /proc/sys/vm/drop_caches
- 下载最新内核版本：https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.12.4.tar.xz
```
#time tar xvf linux-4.12.4.tar.xz
NAS目录时间：19分16秒
ext4目录的时间：24秒
#rm -rf linux-4.12
NAS目录时间：5分48秒
ext4目录的时间：7.2秒
```

