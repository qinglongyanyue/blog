---
layout: default
title:  "如何为git设计文件系统"
date:   2018-03-28
categories: file system
---

# 1. git如何使用存储

近期简单分析了git的存储原理，核心特点如下：

## 1.1 极其小的小文件

我们来看看git的基本动作都对存储做了些啥：

- git init初始化一个仓库，生成.git目录下的一些小文件和目录，比如HEADS, objects，config, info, refs等
- git add了一个新文件test.txt，会在本地文件系统创建一个以文件内容hash为文件名的文件，并写入文件内容
- git commit这个文件，有2个步骤：
  - 会在本地文件系统创建一个以test.txt+文件key为内容的tree对象(几十字节)，其实也是一个小文件，文件名为内容的hash；
  - 创建一个commit对象（小文件），内容为commit填写的消息，提交者信息，文件名为内容的hash。
- 给txt文件添加一行，提交，三个动作：
  - 会在本地文件系统创建一个以文件内容hash为文件名的新文件，并写入文件内容
  - 创建tree对象（同上第一步）
  - 创建commit对象（同上第二步）
- 删除test.txt，git commit这次修改，也有2个步骤：
  - 创建一个新的tree对象，对应的内容为空；
  - 创建一个新的commit对象，内容为commit提交的信息，作者信息，文件名为内容的hash

经过上面一通操作，我们得到了一个啥都没有的仓库，但是后台却相比多了13个小文件，其中objects目录下多了8个小文件。（都是几十字节级别）

此外，打tag，创建新的分支也都会在后台文件系统创建一个小文件,这些文件都比较小，仅仅记录分支或者tag名字，以及对应的commitid。

总之，所有的git更新动作都会对应一个文件，通常这个文件都非常小。一般大型的二进制文件也不太适合放到git中，对于大文件的处理，有个lfs的逻辑，有兴趣的同学可以看看。

## 1.2 垃圾回收

由于git针对每个更新操作都会创建一个新的文件，这样会造成几个问题：

- 随着操作的增加，会有海量极小的文件，一般文件系统比较难以处理这么大规模的小文件，一般文件系统都是固定大小切块，比如2KB，4KB之类的，存储数十字节的文件也不利用空间利用率。
- 代码仓库中，绝大多数的代码修改都是对现有代码做极其少量的修改，每次修改都对应一个全量的文件显然不太经济，大量重复的数据会造成极大的空间浪费。

于是为了解决上面的问题，git提供了GC的逻辑，在代码仓库主动敲git gc，或者当小文件数据到一定程度（默认7000），都会触发git gc动作。针对上面那个仓库，敲完git gc之后，objects下所有的对象都消失了，变成了2个文件。一个是.idx文件，一个是.pack文件。

其中.idx文件是.pack文件的索引，主要是为了快速检索出pack文件的内容，没有.idx文件其实也可以找到我们需要的信息，只是需要全局扫描.pack文件。

打开看看pack文件的细节，可以发现之前objects目录下的8个objects文件都在里面一次排列着呢。

```
>git verify-pack -v .git/objects/pack/pack-a1899e0a29a77132f8c9f5a193dab3557d2e9a07.idx
78b03283d14083af4e88fc30f8a7e7c1669eb992 commit 220 147 12
df0a033ec9eaa0fc35d9260e8224575e45d4c288 commit 220 147 159
813b71f0904b5b33a9a569795d3fff60c5fd029b commit 172 120 306
4b825dc642cb6eb9a060e54bf8d69288fbee4904 tree   0 9 426
eddf172553d649993832a56d0e906c1af0cbabbd tree   36 47 435
5cebb102dc5789f255b039598aad66b84b7620b1 blob   5 14 482
5efb9bc29c482e023e40e0a2b3b7e49cec842034 tree   36 47 496
e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 blob   0 9 543
non delta: 8 objects
.git/objects/pack/pack-a1899e0a29a77132f8c9f5a193dab3557d2e9a07.pack: ok
```

pack文件中的具体含义如下：

- 第一列是内容的hash值（key）
- 第二列是数据的类型
- 第三列是内容的长度
- 第四列是内容在pack文件中的实际长度（经过编码之后）
- 第五列是内容在pack文件中的偏移地址，很容易发现第四和第五列之和等于下一列的第五列

上面这个pack文件没有模拟一个大源码文件，修改一行的逻辑，我们模拟下，可以发现pack文件会多出一种类型，如下所示：

```
05408d195263d853f09dca71d55116663690c27c blob   12908 3478 874
...
9bc1dc421dcd51b4ac296e3e5b6e2a99cf44391e blob   7 18 5193 1 \
  05408d195263d853f09dca71d55116663690c27c
...
```

其中可以发现：

- 第二个blob文件引用了第一个blob文件的内容，仅仅存放了差异，其中的1代表第一个版本，后面跟的key代表基准文件，这样2份代码文件就能通过delta的方式来实现内容的去重。

从存储的角度来看，git gc主要做的事情：

- 读取小文件内容，以append的方式写入到pack文件中，再以append的方式更新idx，最后删除这个小文件
- 如果发现内容与已有的文件有大面积重复(最简单的方法，根据同名的文件来check)，则仅记录delta信息，并存储引用信息

从负载特征来看，gc的时候有大量对极小文件的读IO，以及有一些对pack文件随机小读（读取base文件计算delta），以及对pack文件和idx文件的大量极小的append的写入。

## 1.4 git push

1.1节简单描述了下git add，git commit的逻辑，commit之后调用git push会将commit的修改提交到远程仓库，主要是小文件的创建和写入动作。

## 1.3 git clone & fetch

由于所有的更新git仓库都会记录，除了gc能稍微减缓一些空间压力之外，总体来看git仓库会随着时间推移持续长大。比如我们的linux仓库，持续这么多年的持续更新，当前已经提交接近75万次，那么这个仓库有多大呢？

我刚才git clone试验了下，一个多小时大约就下载了10%左右，全部clone完成预计需要一个晚上，数据量应该有几个GB了。那么clone动作如何执行的呢？

- 首先到仓库获取 info/refs文件，里面存放了每个分支指针，比如master分支，develop分支，包括打的tags

```
登录后台仓库
cat info/refs
830f09e72a1cb81d2c50d0db005d51308c2c181c	refs/heads/master
d7a83b3f7fd35c34b3fa446e33afdfe2625c260c	refs/heads/develop
d7a83b3f7fd35c34b3fa446e33afdfe2625c260c	refs/tags/1.0
```

- 根据refs信息获取master的commit的key，根据key拉取对象，如果对象不存在，直接拉取idx文件和pack文件
- 下载完成之后，把master分支内容在本地解析出来放入本地文件系统中，也就是我们能看懂的源码目录了
- 以同样的方式继续下载其他分支的内容

fetch的时候略有不同：

- 首先到server侧获取对应分支的最新提交信息，与本地的对比
- 如果发现有更新的提交，直接读取更新的内容到本地

基本可见，git clone和fetch不太相同，一般大型的仓库来说，git clone更多的是相对较大的pack文件的读取，而git fetch则是小文件的读取动作。

# 2. 如何为git仓库设计存储

一般情况下，git仓库的部署模式为多个gitlab servers，后台挂一个或者多个共享的NFS目录；大量的读请求都通过gitlab server的本地cache搞定，落到盘上的IO只有小部分的读和写，我们重点考虑下如何为gitlab的写模式设计存储。

## 2.1 元数据设计

首先我们探讨下元数据的设计：

- 从git的原理可见，在海量仓库的情况下，git后台会创建大量的目录和小文件，如何高速的创建文件和目录是git存储的关键
- 在小文件达到一定程度时，git gc又会将小文件组成一个大的pack文件，然后删除这些小文件，需要删除效率很高效
- 由于研发场景是有周期的，一般程序员工作的时候会有大量的提交，其他时间业务比较空闲

所以针对元数据设计思路如下：

- 通过基于LSM tree的KVDB来解决元数据的写入问题，比如RocksDB或者LevelDB
- 批量写入到达时，通过WAL log聚合所有的IO，然后对上层业务返回
- 将WAL写入内存，并针对key排序（key为父目录id，确保同一个目录的文件都排在一起）
- 内存中排序完成之后，直接dump到盘上，避免随机的多次写入，提升写的吞吐量
- 对于删除动作也是append写入，后台再做垃圾回收
- 控制在空闲时候进行垃圾回收，避免垃圾回收影响正常业务

## 2.2 数据设计
我们再讨论下数据IO的设计：

- 对于开发者用的比较多代码的push，fetch等动作，主要是小文件的写入和读取，写入主要是新的内容，基本不对现有内容修改
- 对于全量的代码mirror push或者git clone，主要是大文件的读写
- 对于GC主要是小文件读和大文件的写入，以及数据的删除
- 对于diff操作，主要是小块的读IO（直接读取源码文件，或者从pack中读取源码内容）

所有针对数据IO的思路如下：

- 读的问题我们重点交给上层各级缓存
- 数据层直接申请一个个大的chunk（比如最大64MB），对于小文件写入，直接append到chunk中
  - 无需根据key排序，直接根据进来的IO排序，可以省去WAL和排序的开销
  - 删除的时候仅记录删除动作，数据后台GC完成
- 对于大文件（pack文件），申请一个独立的chunk供他使用；可以通过首次IO的大小来判断是否大文件（比如超过64KB我们认为是大文件，否则是小文件）

## 2.3 实际表现

通过实际测试，在元数据操作方面，我们新的设计思路性能全面超越ext4 2倍以上，除了ls操作略有劣势，其他操作性能明显占优。

在IO路径上，小文件IO性能和大文件小IO性能均超越了ext4的能力。

具体数据图表待补充。